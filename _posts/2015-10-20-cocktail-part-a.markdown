---
layout: post
title:  "Cocktail Part A"
date:   2015-10-20 1:22:15
categories: projects music
---

In July 2015, friend and composer Richard Warp and I set out to make an installation for the [Mozart and the Mind](http://www.mainlymozart.org/mozart-and-the-mind/mozart-the-mind-the-prodigal-years/) conference. Our goal was to develop software that would algorithmically transform a conversation into a unique musical composition in real-time. For computer music, I had always turned to Max/MSP, but felt that it's building-block style made it difficult to work in more conventional program flow, data analysis, and machine learning. That's when I discovered the fantastic python module [pyo](http://ajaxsoundstudio.com/software/pyo/), a library for real-time audio synthesis. I am planning on writing a blog post detailing my exploits, but for now, you can at least check out the results.

Artist statement:

> Conversation is the heart of the cocktail party. Through conversation we share our ideas and stories, and we mix our voices in an ever-changing sonic scene. Spoken language facilitates this mixture in it two ways: it is semantic: a vessel for thought, communication of abstract ideas, poetry, scientific concepts. As a semantic entity, words enable people to gather in the social plane, a shared and collaborative mental space. Speech is also sensory: rhythmic, tonal, and musical. Each person's voice is uniquely theirs, immediately and reliably signifying the individual who produced the message.> 

> In an age that has adopted text as the de facto standard for communication, we often experience the message without the music, but voice sans message has its own allure. You may have encountered it, perhaps as a child in bed, hearing the murmurs of your parents in the next room. Or perhaps as a traveller in a foreign country, overhearing voices conversing in an unfamiliar language. When words are stripped of their literal meaning, their music elevates to the forefront of our attention.> 

> In this installation, we turn a spotlight onto this music and to the shared social space that it inhabits. Four "performers" equipped with portable EEG and voice recorders will engage in friendly cocktail party conversation. EEG and vocal output will stream to our base station, which will analyze the presence and flow of attention in this ad hoc social network. Utterances will be sampled, their linguistic meaning removed, and their musical features enhanced. An algorithm will layer and persist the samples according to the significance of their source in the social plane. By pointing out the musicality of language, we hope to convey the seed of prodigy in us all.

Here is one conversation, which we recorded during a demonstration for the course *EE 16B. Designing Information Devices and Systems II* at UC Berkeley.

<iframe width="60%" height="150" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/229330702&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;visual=true"></iframe>

This project is still under active development. We will present it in October at [Spectrum](http://www.spectrumnyc.com/).